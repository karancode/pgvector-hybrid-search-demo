{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d87613-0996-4e8e-b40c-989c708eaf78",
   "metadata": {},
   "source": [
    "## Hybrid Search with Amazon RDS and Amazon Aurora PostgreSQL using pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0495eab-d066-4a7e-bfdb-a43808c9c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the required prerequiste libraries - approx 3 min to complete\n",
    "%pip install -U pgvector pandarallel boto3 psycopg numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a0b7c82-5f50-4b1c-95f9-e4a99793e441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records : 9729\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_specification</th>\n",
       "      <th>product_details</th>\n",
       "      <th>image_url</th>\n",
       "      <th>all_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4c69b61db1fc16e7013b43fc926e502d</td>\n",
       "      <td>DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...</td>\n",
       "      <td>Sports &amp; Outdoors | Outdoor Recreation | Skate...</td>\n",
       "      <td>Make sure this fits by entering your model num...</td>\n",
       "      <td>Shipping Weight: 10.7 pounds (View shipping ra...</td>\n",
       "      <td></td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>Make sure this fits by entering your model num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66d49bbed043f5be260fa9f7fbff5957</td>\n",
       "      <td>Electronic Snap Circuits Mini Kits Classpack, ...</td>\n",
       "      <td>Toys &amp; Games | Learning &amp; Education | Science ...</td>\n",
       "      <td>Make sure this fits by entering your model num...</td>\n",
       "      <td>Product Dimensions:         14.7 x 11.1 x 10.2...</td>\n",
       "      <td>The snap circuits mini kits classpack provides...</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>Make sure this fits by entering your model num...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  4c69b61db1fc16e7013b43fc926e502d   \n",
       "1  66d49bbed043f5be260fa9f7fbff5957   \n",
       "\n",
       "                                        product_name  \\\n",
       "0  DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...   \n",
       "1  Electronic Snap Circuits Mini Kits Classpack, ...   \n",
       "\n",
       "                                            category  \\\n",
       "0  Sports & Outdoors | Outdoor Recreation | Skate...   \n",
       "1  Toys & Games | Learning & Education | Science ...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  Make sure this fits by entering your model num...   \n",
       "1  Make sure this fits by entering your model num...   \n",
       "\n",
       "                               product_specification  \\\n",
       "0  Shipping Weight: 10.7 pounds (View shipping ra...   \n",
       "1  Product Dimensions:         14.7 x 11.1 x 10.2...   \n",
       "\n",
       "                                     product_details  \\\n",
       "0                                                      \n",
       "1  The snap circuits mini kits classpack provides...   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images-na.ssl-images-amazon.com/images...   \n",
       "1  https://images-na.ssl-images-amazon.com/images...   \n",
       "\n",
       "                                    all_descriptions  \n",
       "0  Make sure this fits by entering your model num...  \n",
       "1  Make sure this fits by entering your model num...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data from csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/marketing_sample_for_amazon_com-ecommerce_10k_data.csv')\n",
    "\n",
    "df = df[['Uniq Id','Product Name','Category','About Product','Product Specification','Technical Details','Image']]\n",
    "\n",
    "df = df.dropna(subset=['About Product'])\n",
    "df = df.fillna('')\n",
    "df.rename(columns={'Uniq Id': 'id', \n",
    "                   'Product Name': 'product_name',\n",
    "                   'Category':'category',\n",
    "                   'About Product':'product_description',\n",
    "                   'Product Specification':'product_specification',\n",
    "                   'Technical Details':'product_details',\n",
    "                   'Image':'image_url'}, inplace=True)\n",
    "\n",
    "df['all_descriptions'] = df['product_description'] + df['product_specification'] + df['product_details']\n",
    "\n",
    "print(\"Total number of records : {}\".format(len(df.index)))\n",
    "\n",
    "display(df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4645b46-0cd0-4104-ad98-f6c21e5bcc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vector embeddings of the product description using Amazon Titan Embeddings model hosted in Amazon Bedrock service\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "def generate_embeddings(query):\n",
    "    \n",
    "    payLoad = json.dumps({'inputText': query })\n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=payLoad, \n",
    "        modelId='amazon.titan-embed-g1-text-02',\n",
    "        accept=\"application/json\", \n",
    "        contentType=\"application/json\" )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    return(response_body.get(\"embedding\"))\n",
    "    \n",
    "description_embeddings = generate_embeddings(df.iloc[1].get('all_descriptions'))\n",
    "\n",
    "print (\"Number of dimensions : {}\".format(len(description_embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174c984-f38d-4831-9f01-4b376c3530ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all the products descriptions - approx 3 min to complete\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=8)\n",
    "\n",
    "# Generate Embeddings for all the products \n",
    "df['description_embeddings'] = df['all_descriptions'].parallel_apply(generate_embeddings)\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(\"Completed generation of embeddings for all the products descriptions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a655e7f-82ce-42eb-ad1b-dcfc935e11ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all the product data with description text and embeddings into Amazon Aurora PostgreSQL database using pgvector\n",
    "\n",
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "import boto3 \n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "client = boto3.client('secretsmanager')\n",
    "\n",
    "response = client.get_secret_value(SecretId='secret/hybrid-search-aurorapg')\n",
    "database_secrets = json.loads(response['SecretString'])\n",
    "\n",
    "dbhost = database_secrets['host']\n",
    "dbport = database_secrets['port']\n",
    "dbuser = database_secrets['username']\n",
    "dbpass = database_secrets['password']\n",
    "\n",
    "dbconn = psycopg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport, connect_timeout=10, autocommit=True)\n",
    "\n",
    "# Enable the pgvector extension\n",
    "dbconn.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "register_vector(dbconn)\n",
    "\n",
    "# Create the products table\n",
    "dbconn.execute(\"DROP TABLE IF EXISTS products;\")\n",
    "\n",
    "dbconn.execute(\"\"\"CREATE TABLE IF NOT EXISTS products(\n",
    "                   id text primary key, \n",
    "                   product_name text, \n",
    "                   category text, \n",
    "                   product_description text, \n",
    "                   product_specification text,\n",
    "                   product_details text,   \n",
    "                   image_url text,\n",
    "                   description_text text,\n",
    "                   description_embeddings vector(1536));\"\"\")\n",
    "\n",
    "# Insert the product data\n",
    "for _, x in df.iterrows():\n",
    "    dbconn.execute(\"\"\"INSERT INTO products\n",
    "                  (id, product_name, category, product_description, product_specification, product_details, image_url, description_text, description_embeddings) \n",
    "                   VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s);\"\"\", \n",
    "                   (x.get('id'), x.get('product_name'), x.get('category'), x.get('product_description'), x.get('product_specification'), x.get('product_details'), x.get('image_url'), x.get('all_descriptions'), x.get('description_embeddings')))\n",
    "\n",
    "# Create GIN index for the product description text field for lexical search\n",
    "dbconn.execute(\"\"\"CREATE INDEX idx_products_description_text_tsvector ON products\n",
    "                  USING gin(to_tsvector('english', description_text));\"\"\")\n",
    "\n",
    "# Create HNSW index for the product description embeddings feild for vector similarity search\n",
    "dbconn.execute(\"\"\"CREATE INDEX ON products \n",
    "                   USING hnsw (description_embeddings vector_cosine_ops) \n",
    "                   WITH  (m = 16, ef_construction = 64);\"\"\")\n",
    "\n",
    "dbconn.execute(\"VACUUM ANALYZE products;\")\n",
    "\n",
    "dbconn.close()\n",
    "print (\"Data has been successfully loaded into Aurora PostgreSQL tables \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2260f0a9-11b7-495d-9f63-91e0750d2055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical search results for 'halloween decoration':\n",
      "\n"
     ]
    },
    {
     "ename": "ConnectionTimeout",
     "evalue": "connection timeout expired",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionTimeout\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     dbconn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLexical search results for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhalloween decoration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mlexical_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhalloween decoration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m, in \u001b[0;36mlexical_search\u001b[0;34m(search_text)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlexical_search\u001b[39m(search_text):\n\u001b[0;32m----> 7\u001b[0m     dbconn \u001b[38;5;241m=\u001b[39m \u001b[43mpsycopg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbuser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbpass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnect_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     register_vector(dbconn)\n\u001b[1;32m     10\u001b[0m     r\u001b[38;5;241m=\u001b[39m dbconn\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mSELECT id, image_url, product_name, product_description, product_details\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m                         FROM products \u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m                         WHERE to_tsvector(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, description_text) @@ plainto_tsquery(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m                         ORDER BY ts_rank(to_tsvector(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, description_text), plainto_tsquery(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)) DESC\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m                         LIMIT 5;\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m,(search_text, search_text))\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/psycopg/connection.py:119\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(cls, conninfo, autocommit, prepare_threshold, context, row_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rv:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m last_ex\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m last_ex\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    121\u001b[0m rv\u001b[38;5;241m.\u001b[39m_autocommit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(autocommit)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row_factory:\n",
      "\u001b[0;31mConnectionTimeout\u001b[0m: connection timeout expired"
     ]
    }
   ],
   "source": [
    "#  Evaluate PostgreSQL lexical search results\n",
    "import numpy\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "\n",
    "\n",
    "def lexical_search(search_text):\n",
    "    dbconn = psycopg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport, connect_timeout=10)\n",
    "    register_vector(dbconn)\n",
    "    \n",
    "    r= dbconn.execute(\"\"\"SELECT id, image_url, product_name, product_description, product_details\n",
    "                         FROM products \n",
    "                         WHERE to_tsvector('english', description_text) @@ plainto_tsquery('english', %s)\n",
    "                         ORDER BY ts_rank(to_tsvector('english', description_text), plainto_tsquery('english', %s)) DESC\n",
    "                         LIMIT 5;\"\"\",(search_text, search_text)).fetchall()\n",
    "    \n",
    "    img_td = \"\"\n",
    "    for x in r:\n",
    "        url = x[1].split(\"|\")[0]\n",
    "        img_td = img_td + \"\"\"<tr><td><img src={} width=\"1000\"></td>\"\"\".format(url)\n",
    "        img_td = img_td + \"\"\"<td style=\"text-align: left; vertical-align: top;\"> <h3>{}</h3> <p>{}</p></td></tr>\"\"\".format(str(x[2]),str(x[4]))\n",
    "       \n",
    "    display(HTML(\"\"\"<table>{}</table>\"\"\".format(img_td)))\n",
    "    dbconn.close()\n",
    "\n",
    "print(\"Lexical search results for 'halloween decoration':\\n\")\n",
    "lexical_search(\"halloween decoration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e4a826d-a88f-4e5e-b56a-1f2a6d5d142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity search results for 'halloween decoration':\n",
      "\n"
     ]
    },
    {
     "ename": "ConnectionTimeout",
     "evalue": "connection timeout expired",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionTimeout\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     dbconn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilarity search results for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhalloween decoration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhalloween decoration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m, in \u001b[0;36msimilarity_search\u001b[0;34m(search_text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(search_text):\n\u001b[1;32m      4\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(generate_embeddings(search_text))\n\u001b[0;32m----> 5\u001b[0m     dbconn \u001b[38;5;241m=\u001b[39m \u001b[43mpsycopg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbuser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbpass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnect_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     register_vector(dbconn)\n\u001b[1;32m      8\u001b[0m     r\u001b[38;5;241m=\u001b[39m dbconn\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mSELECT id, image_url, product_name, product_description, product_details\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m                         FROM products \u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m                         ORDER BY description_embeddings <=> \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m limit 5;\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m,(embedding,))\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/psycopg/connection.py:119\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(cls, conninfo, autocommit, prepare_threshold, context, row_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rv:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m last_ex\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m last_ex\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    121\u001b[0m rv\u001b[38;5;241m.\u001b[39m_autocommit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(autocommit)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row_factory:\n",
      "\u001b[0;31mConnectionTimeout\u001b[0m: connection timeout expired"
     ]
    }
   ],
   "source": [
    "# Evaluate PostgreSQL vector search results\n",
    "def similarity_search(search_text):\n",
    "    \n",
    "    embedding = numpy.array(generate_embeddings(search_text))\n",
    "    dbconn = psycopg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport, connect_timeout=10)\n",
    "    register_vector(dbconn)\n",
    "    \n",
    "    r= dbconn.execute(\"\"\"SELECT id, image_url, product_name, product_description, product_details\n",
    "                         FROM products \n",
    "                         ORDER BY description_embeddings <=> %s limit 5;\"\"\",(embedding,)).fetchall()\n",
    "   \n",
    "    img_td = \"\"\n",
    "    for x in r:\n",
    "        url = x[1].split(\"|\")[0]\n",
    "        img_td = img_td + \"\"\"<tr><td><img src={} width=\"1000\"></td>\"\"\".format(url)\n",
    "        img_td = img_td + \"\"\"<td style=\"text-align: left; vertical-align: top;\"> <h3>{}</h3> <p>{}</p></td></tr>\"\"\".format(str(x[2]),str(x[4]))\n",
    "       \n",
    "    display(HTML(\"\"\"<table>{}</table>\"\"\".format(img_td)))\n",
    "    dbconn.close()\n",
    "\n",
    "print(\"Similarity search results for 'halloween decoration':\\n\")\n",
    "similarity_search(\"halloween decoration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15cce9-98cd-4712-b75a-5d741194d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate PostgreSQL hybrid search results\n",
    "\n",
    "def hybrid_search(search_text):\n",
    "    embedding = numpy.array(generate_embeddings(search_text))\n",
    "    dbconn = psycopg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport, connect_timeout=10)\n",
    "    register_vector(dbconn)\n",
    "\n",
    "    # prioritizing semantic results (left join)\n",
    "    r= dbconn.execute(\"\"\"WITH semantic_results AS (\n",
    "                             SELECT id, \n",
    "                             image_url, \n",
    "                             product_name, \n",
    "                             product_description, \n",
    "                             product_details,\n",
    "                             1 - (description_embeddings <=> %s) AS semantic_similarity\n",
    "                             FROM products\n",
    "                             ORDER BY description_embeddings <=> %s\n",
    "                             LIMIT 100\n",
    "                        ),\n",
    "                        lexical_results AS (\n",
    "                             SELECT id, \n",
    "                             ts_rank(to_tsvector('english', description_text), plainto_tsquery('english', %s)) AS lexical_rank\n",
    "                             FROM products\n",
    "                             WHERE to_tsvector('english', description_text) @@ plainto_tsquery('english', %s)\n",
    "                        )\n",
    "                        SELECT sr.id, \n",
    "                               sr.image_url, \n",
    "                               sr.product_name, \n",
    "                               sr.product_description,   \n",
    "                               sr.product_details,\n",
    "                               sr.semantic_similarity * 0.7 + COALESCE(lr.lexical_rank, 0) * 0.3 AS hybrid_score\n",
    "                        FROM semantic_results sr\n",
    "                        LEFT JOIN lexical_results lr ON sr.id = lr.id\n",
    "                        ORDER BY hybrid_score DESC\n",
    "                        LIMIT 5;\"\"\",(embedding,embedding,search_text,search_text)).fetchall()\n",
    "\n",
    "    # include all results from semantic and lexical search (outer join) \n",
    "    r_outerjoin = dbconn.execute(\"\"\"WITH semantic_results AS (\n",
    "  SELECT id, \n",
    "         image_url, \n",
    "         product_name, \n",
    "         product_description, \n",
    "         product_details,\n",
    "         1 - (description_embeddings <=> %s) AS semantic_similarity\n",
    "  FROM products\n",
    "  ORDER BY description_embeddings <=> %s\n",
    "  LIMIT 1000  -- Increased limit to capture more potential matches\n",
    "),\n",
    "lexical_results AS (\n",
    "  SELECT id, \n",
    "         ts_rank(to_tsvector('english', description_text), plainto_tsquery('english', %s)) AS lexical_rank\n",
    "  FROM products\n",
    "  WHERE to_tsvector('english', description_text) @@ plainto_tsquery('english', %s)\n",
    ")\n",
    "SELECT \n",
    "    COALESCE(sr.id, lr.id) AS id,\n",
    "    sr.image_url, \n",
    "    sr.product_name, \n",
    "    sr.product_description, \n",
    "    sr.product_details,\n",
    "    COALESCE(sr.semantic_similarity, 0) * 0.6 + COALESCE(lr.lexical_rank, 0) * 0.4 AS hybrid_score\n",
    "FROM semantic_results sr\n",
    "FULL OUTER JOIN lexical_results lr ON sr.id = lr.id\n",
    "ORDER BY hybrid_score DESC\n",
    "LIMIT 5;\"\"\",(embedding,embedding,search_text,search_text)).fetchall()\n",
    "\n",
    "    \n",
    "    img_td = \"\"\n",
    "    for x in r_outerjoin:\n",
    "        url = x[1].split(\"|\")[0]\n",
    "        img_td = img_td + \"\"\"<tr><td><img src={} width=\"1000\"></td>\"\"\".format(url)\n",
    "        img_td = img_td + \"\"\"<td style=\"text-align: left; vertical-align: top;\"> <h3>{}</h3> <p>{}</p></td></tr>\"\"\".format(str(x[2]),str(x[4]))\n",
    "       \n",
    "    display(HTML(\"\"\"<table>{}</table>\"\"\".format(img_td)))\n",
    "    dbconn.close()\n",
    "\n",
    "print(\"Hybrid search results for 'halloween decoration':\\n\")\n",
    "hybrid_search(\"halloween decoration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0966b1-bc64-46b1-8af6-e0ec9a3dc5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "385cfc07",
   "metadata": {},
   "source": [
    "## Hybrid Search with Amazon RDS and Amazon Aurora PostgreSQL using pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the required prerequiste libraries - approx 3 min to complete\n",
    "%pip install -U pgvector pandarallel boto3 psycopg numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "473494c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records : 9729\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_specification</th>\n",
       "      <th>product_details</th>\n",
       "      <th>image_url</th>\n",
       "      <th>all_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4c69b61db1fc16e7013b43fc926e502d</td>\n",
       "      <td>DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...</td>\n",
       "      <td>Sports &amp; Outdoors | Outdoor Recreation | Skate...</td>\n",
       "      <td>Make sure this fits by entering your model num...</td>\n",
       "      <td>Shipping Weight: 10.7 pounds (View shipping ra...</td>\n",
       "      <td></td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>Make sure this fits by entering your model num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66d49bbed043f5be260fa9f7fbff5957</td>\n",
       "      <td>Electronic Snap Circuits Mini Kits Classpack, ...</td>\n",
       "      <td>Toys &amp; Games | Learning &amp; Education | Science ...</td>\n",
       "      <td>Make sure this fits by entering your model num...</td>\n",
       "      <td>Product Dimensions:         14.7 x 11.1 x 10.2...</td>\n",
       "      <td>The snap circuits mini kits classpack provides...</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>Make sure this fits by entering your model num...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  4c69b61db1fc16e7013b43fc926e502d   \n",
       "1  66d49bbed043f5be260fa9f7fbff5957   \n",
       "\n",
       "                                        product_name  \\\n",
       "0  DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...   \n",
       "1  Electronic Snap Circuits Mini Kits Classpack, ...   \n",
       "\n",
       "                                            category  \\\n",
       "0  Sports & Outdoors | Outdoor Recreation | Skate...   \n",
       "1  Toys & Games | Learning & Education | Science ...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  Make sure this fits by entering your model num...   \n",
       "1  Make sure this fits by entering your model num...   \n",
       "\n",
       "                               product_specification  \\\n",
       "0  Shipping Weight: 10.7 pounds (View shipping ra...   \n",
       "1  Product Dimensions:         14.7 x 11.1 x 10.2...   \n",
       "\n",
       "                                     product_details  \\\n",
       "0                                                      \n",
       "1  The snap circuits mini kits classpack provides...   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images-na.ssl-images-amazon.com/images...   \n",
       "1  https://images-na.ssl-images-amazon.com/images...   \n",
       "\n",
       "                                    all_descriptions  \n",
       "0  Make sure this fits by entering your model num...  \n",
       "1  Make sure this fits by entering your model num...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data from csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/marketing_sample_for_amazon_com-ecommerce_10k_data.csv')\n",
    "\n",
    "df = df[['Uniq Id','Product Name','Category','About Product','Product Specification','Technical Details','Image']]\n",
    "\n",
    "df = df.dropna(subset=['About Product'])\n",
    "df = df.fillna('')\n",
    "df.rename(columns={'Uniq Id': 'id', \n",
    "                   'Product Name': 'product_name',\n",
    "                   'Category':'category',\n",
    "                   'About Product':'product_description',\n",
    "                   'Product Specification':'product_specification',\n",
    "                   'Technical Details':'product_details',\n",
    "                   'Image':'image_url'}, inplace=True)\n",
    "\n",
    "df['all_descriptions'] = df['product_description'] + df['product_specification'] + df['product_details']\n",
    "\n",
    "print(\"Total number of records : {}\".format(len(df.index)))\n",
    "\n",
    "display(df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f6a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vector embeddings of the product description using Amazon Titan Embeddings model hosted in Amazon Bedrock service\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "def generate_embeddings(query):\n",
    "    \n",
    "    payLoad = json.dumps({'inputText': query })\n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=payLoad, \n",
    "        modelId='amazon.titan-embed-g1-text-02',\n",
    "        accept=\"application/json\", \n",
    "        contentType=\"application/json\" )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    return(response_body.get(\"embedding\"))\n",
    "    \n",
    "description_embeddings = generate_embeddings(df.iloc[1].get('all_descriptions'))\n",
    "\n",
    "print (\"Number of dimensions : {}\".format(len(description_embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca773a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all the products descriptions - approx 3 min to complete\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=8)\n",
    "\n",
    "# Generate Embeddings for all the products \n",
    "df['description_embeddings'] = df['all_descriptions'].parallel_apply(generate_embeddings)\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(\"Completed generation of embeddings for all the products descriptions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a30b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all the product data with description text and embeddings into Amazon Aurora PostgreSQL database using pgvector\n",
    "\n",
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "import boto3 \n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "client = boto3.client('secretsmanager')\n",
    "\n",
    "response = client.get_secret_value(SecretId='secret/hybrid-search-aurorapg')\n",
    "database_secrets = json.loads(response['SecretString'])\n",
    "\n",
    "dbhost = database_secrets['host']\n",
    "dbport = database_secrets['port']\n",
    "dbuser = database_secrets['username']\n",
    "dbpass = database_secrets['password']\n",
    "\n",
    "dbconn = psycopg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport, connect_timeout=10, autocommit=True)\n",
    "\n",
    "# Enable the pgvector extension\n",
    "dbconn.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "register_vector(dbconn)\n",
    "\n",
    "# Create the products table\n",
    "dbconn.execute(\"DROP TABLE IF EXISTS products;\")\n",
    "\n",
    "dbconn.execute(\"\"\"CREATE TABLE IF NOT EXISTS products(\n",
    "                   id text primary key, \n",
    "                   product_name text, \n",
    "                   category text, \n",
    "                   product_description text, \n",
    "                   product_specification text,\n",
    "                   product_details text,   \n",
    "                   image_url text,\n",
    "                   description_text text,\n",
    "                   description_embeddings vector(1536));\"\"\")\n",
    "\n",
    "# Insert the product data\n",
    "for _, x in df.iterrows():\n",
    "    dbconn.execute(\"\"\"INSERT INTO products\n",
    "                  (id, product_name, category, product_description, product_specification, product_details, image_url, description_text, description_embeddings) \n",
    "                   VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s);\"\"\", \n",
    "                   (x.get('id'), x.get('product_name'), x.get('category'), x.get('product_description'), x.get('product_specification'), x.get('product_details'), x.get('image_url'), x.get('all_descriptions'), x.get('description_embeddings')))\n",
    "\n",
    "# Create GIN index for the product description text field for lexical search\n",
    "dbconn.execute(\"\"\"CREATE INDEX idx_products_description_text_tsvector ON products\n",
    "                  USING gin(to_tsvector('english', description_text));\"\"\")\n",
    "\n",
    "# Create HNSW index for the product description embeddings feild for vector similarity search\n",
    "dbconn.execute(\"\"\"CREATE INDEX ON products \n",
    "                   USING hnsw (description_embeddings vector_cosine_ops) \n",
    "                   WITH  (m = 16, ef_construction = 64);\"\"\")\n",
    "\n",
    "dbconn.execute(\"VACUUM ANALYZE products;\")\n",
    "\n",
    "dbconn.close()\n",
    "print (\"Data has been successfully loaded into Aurora PostgreSQL tables \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02403a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Evaluate PostgreSQL lexical search results\n",
    "import numpy\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "\n",
    "\n",
    "def lexical_search(search_text):\n",
    "    dbconn = psycopg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport, connect_timeout=10)\n",
    "    register_vector(dbconn)\n",
    "    \n",
    "    r= dbconn.execute(\"\"\"SELECT id, image_url, product_name, product_description, product_details\n",
    "                         FROM products \n",
    "                         WHERE to_tsvector('english', description_text) @@ plainto_tsquery('english', %s)\n",
    "                         ORDER BY ts_rank(to_tsvector('english', description_text), plainto_tsquery('english', %s)) DESC\n",
    "                         LIMIT 5;\"\"\",(search_text, search_text)).fetchall()\n",
    "    \n",
    "    img_td = \"\"\n",
    "    for x in r:\n",
    "        url = x[1].split(\"|\")[0]\n",
    "        img_td = img_td + \"\"\"<tr><td><img src={} width=\"1000\"></td>\"\"\".format(url)\n",
    "        img_td = img_td + \"\"\"<td style=\"text-align: left; vertical-align: top;\"> <h3>{}</h3> <p>{}</p></td></tr>\"\"\".format(str(x[2]),str(x[4]))\n",
    "       \n",
    "    display(HTML(\"\"\"<table>{}</table>\"\"\".format(img_td)))\n",
    "    dbconn.close()\n",
    "\n",
    "print(\"Lexical search results for 'halloween decoration':\\n\")\n",
    "lexical_search(\"halloween decoration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate PostgreSQL vector search results\n",
    "def similarity_search(search_text):\n",
    "    \n",
    "    embedding = numpy.array(generate_embeddings(search_text))\n",
    "    dbconn = psycopg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport, connect_timeout=10)\n",
    "    register_vector(dbconn)\n",
    "    \n",
    "    r= dbconn.execute(\"\"\"SELECT id, image_url, product_name, product_description, product_details\n",
    "                         FROM products \n",
    "                         ORDER BY description_embeddings <=> %s limit 5;\"\"\",(embedding,)).fetchall()\n",
    "   \n",
    "    img_td = \"\"\n",
    "    for x in r:\n",
    "        url = x[1].split(\"|\")[0]\n",
    "        img_td = img_td + \"\"\"<tr><td><img src={} width=\"1000\"></td>\"\"\".format(url)\n",
    "        img_td = img_td + \"\"\"<td style=\"text-align: left; vertical-align: top;\"> <h3>{}</h3> <p>{}</p></td></tr>\"\"\".format(str(x[2]),str(x[4]))\n",
    "       \n",
    "    display(HTML(\"\"\"<table>{}</table>\"\"\".format(img_td)))\n",
    "    dbconn.close()\n",
    "\n",
    "print(\"Similarity search results for 'halloween decoration':\\n\")\n",
    "similarity_search(\"halloween decoration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da790318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid search results for 'halloween decoration':\n",
      "\n"
     ]
    },
    {
     "ename": "ConnectionTimeout",
     "evalue": "connection timeout expired",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionTimeout\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m     dbconn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHybrid search results for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhalloween decoration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m \u001b[43mhybrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhalloween decoration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m, in \u001b[0;36mhybrid_search\u001b[0;34m(search_text)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhybrid_search\u001b[39m(search_text):\n\u001b[1;32m      4\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(generate_embeddings(search_text))\n\u001b[0;32m----> 5\u001b[0m     dbconn \u001b[38;5;241m=\u001b[39m \u001b[43mpsycopg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbuser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbpass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnect_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     register_vector(dbconn)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# prioritizing semantic results (left join)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/psycopg/connection.py:119\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(cls, conninfo, autocommit, prepare_threshold, context, row_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rv:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m last_ex\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m last_ex\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    121\u001b[0m rv\u001b[38;5;241m.\u001b[39m_autocommit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(autocommit)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row_factory:\n",
      "\u001b[0;31mConnectionTimeout\u001b[0m: connection timeout expired"
     ]
    }
   ],
   "source": [
    "# Evaluate PostgreSQL hybrid search results\n",
    "\n",
    "def hybrid_search(search_text):\n",
    "    embedding = numpy.array(generate_embeddings(search_text))\n",
    "    dbconn = psycopg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport, connect_timeout=10)\n",
    "    register_vector(dbconn)\n",
    "\n",
    "    # prioritizing semantic results (left join)\n",
    "    r= dbconn.execute(\"\"\"WITH semantic_results AS (\n",
    "                             SELECT id, \n",
    "                             image_url, \n",
    "                             product_name, \n",
    "                             product_description, \n",
    "                             product_details,\n",
    "                             1 - (description_embeddings <=> %s) AS semantic_similarity\n",
    "                             FROM products\n",
    "                             ORDER BY description_embeddings <=> %s\n",
    "                             LIMIT 100\n",
    "                        ),\n",
    "                        lexical_results AS (\n",
    "                             SELECT id, \n",
    "                             ts_rank(to_tsvector('english', description_text), plainto_tsquery('english', %s)) AS lexical_rank\n",
    "                             FROM products\n",
    "                             WHERE to_tsvector('english', description_text) @@ plainto_tsquery('english', %s)\n",
    "                        )\n",
    "                        SELECT sr.id, \n",
    "                               sr.image_url, \n",
    "                               sr.product_name, \n",
    "                               sr.product_description,   \n",
    "                               sr.product_details,\n",
    "                               sr.semantic_similarity * 0.7 + COALESCE(lr.lexical_rank, 0) * 0.3 AS hybrid_score\n",
    "                        FROM semantic_results sr\n",
    "                        LEFT JOIN lexical_results lr ON sr.id = lr.id\n",
    "                        ORDER BY hybrid_score DESC\n",
    "                        LIMIT 5;\"\"\",(embedding,embedding,search_text,search_text)).fetchall()\n",
    "\n",
    "    # include all results from semantic and lexical search (outer join) \n",
    "    r_outerjoin = dbconn.execute(\"\"\"WITH semantic_results AS (\n",
    "  SELECT id, \n",
    "         image_url, \n",
    "         product_name, \n",
    "         product_description, \n",
    "         product_details,\n",
    "         1 - (description_embeddings <=> %s) AS semantic_similarity\n",
    "  FROM products\n",
    "  ORDER BY description_embeddings <=> %s\n",
    "  LIMIT 1000  -- Increased limit to capture more potential matches\n",
    "),\n",
    "lexical_results AS (\n",
    "  SELECT id, \n",
    "         ts_rank(to_tsvector('english', description_text), plainto_tsquery('english', %s)) AS lexical_rank\n",
    "  FROM products\n",
    "  WHERE to_tsvector('english', description_text) @@ plainto_tsquery('english', %s)\n",
    ")\n",
    "SELECT \n",
    "    COALESCE(sr.id, lr.id) AS id,\n",
    "    sr.image_url, \n",
    "    sr.product_name, \n",
    "    sr.product_description, \n",
    "    sr.product_details,\n",
    "    COALESCE(sr.semantic_similarity, 0) * 0.6 + COALESCE(lr.lexical_rank, 0) * 0.4 AS hybrid_score\n",
    "FROM semantic_results sr\n",
    "FULL OUTER JOIN lexical_results lr ON sr.id = lr.id\n",
    "ORDER BY hybrid_score DESC\n",
    "LIMIT 5;\"\"\",(embedding,embedding,search_text,search_text)).fetchall()\n",
    "\n",
    "    \n",
    "    img_td = \"\"\n",
    "    for x in r_outerjoin:\n",
    "        url = x[1].split(\"|\")[0]\n",
    "        img_td = img_td + \"\"\"<tr><td><img src={} width=\"1000\"></td>\"\"\".format(url)\n",
    "        img_td = img_td + \"\"\"<td style=\"text-align: left; vertical-align: top;\"> <h3>{}</h3> <p>{}</p></td></tr>\"\"\".format(str(x[2]),str(x[4]))\n",
    "       \n",
    "    display(HTML(\"\"\"<table>{}</table>\"\"\".format(img_td)))\n",
    "    dbconn.close()\n",
    "\n",
    "print(\"Hybrid search results for 'halloween decoration':\\n\")\n",
    "hybrid_search(\"halloween decoration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc8df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
